{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c8b942c",
   "metadata": {},
   "source": [
    "## Regresión Logística\n",
    "\n",
    "La **regresión logística** es un modelo estadístico utilizado para predecir una variable dependiente binaria (es decir, con dos posibles valores: 0 o 1) a partir de un conjunto de variables independientes. A diferencia de la regresión lineal, que predice valores continuos, la regresión logística estima la **probabilidad** de que una observación pertenezca a una clase.\n",
    "\n",
    "La función principal que utiliza es la **función sigmoide**:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "donde $ z = X \\cdot \\beta $, y $ \\beta $ representa los pesos del modelo. La salida de la sigmoide es un valor entre 0 y 1, que se interpreta como una probabilidad.\n",
    "\n",
    "El modelo se entrena minimizando la **función de pérdida logarítmica (log-loss)**, la cual penaliza las predicciones incorrectas más severamente cuanto más seguras son.\n",
    "\n",
    "La función de pérdida logarítmica, utilizada para entrenar modelos de regresión logística, se define como:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(\\hat{y}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{y}^{(i)}) \\right]\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $ m $ es el número total de ejemplos,\n",
    "- $ y^{(i)} $ es la etiqueta verdadera (0 o 1),\n",
    "- $ \\hat{y}^{(i)} $ es la probabilidad predicha para la clase positiva,\n",
    "- $ \\log $ es el logaritmo natural.\n",
    "\n",
    "Esta función mide qué tan bien se ajustan las probabilidades predichas a las etiquetas reales, penalizando con mayor severidad las predicciones incorrectas y seguras.\n",
    "\n",
    "La regresión logística es ampliamente utilizada en clasificación binaria, como detección de fraudes, diagnóstico médico, y predicción de abandono de clientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa53281",
   "metadata": {},
   "source": [
    "## Proyecto: Predicción de Riesgo de Hospitalización\n",
    "\n",
    "El **Hospital Regional \"Salud Perfecta\"** busca anticipar qué pacientes tienen un **alto riesgo de hospitalización** en los próximos 6 meses. Para ello, el equipo de ciencia de datos debe desarrollar un modelo predictivo usando **exclusivamente regresión logística** como algoritmo base.\n",
    "\n",
    "### Objetivo\n",
    "Construir un modelo de **clasificación binaria** que prediga la variable objetivo (`target`), la cual indica si un paciente será hospitalizado o no en el futuro cercano.\n",
    "\n",
    "### Datos\n",
    "El conjunto de datos incluye **15 variables predictoras** por paciente, que pueden abarcar factores clínicos, demográficos y hábitos de vida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d011d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40432bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2aa88",
   "metadata": {},
   "source": [
    "## Variables del Conjunto de Datos\n",
    "\n",
    "El conjunto de datos contiene las siguientes **15 variables predictoras** más la variable objetivo (`target`). A continuación se listan junto con su tipo de dato:\n",
    "\n",
    "| Variable                  | Tipo de dato |\n",
    "|---------------------------|--------------|\n",
    "| ratio_colesterol          | float64      |\n",
    "| actividad_fisica          | float64      |\n",
    "| presion_arterial          | float64      |\n",
    "| nivel_glucosa             | float64      |\n",
    "| indice_masa_corporal      | float64      |\n",
    "| horas_sueno               | float64      |\n",
    "| historial_diabetes        | int64        |\n",
    "| frecuencia_cardiaca       | float64      |\n",
    "| proteina_c_reactiva       | float64      |\n",
    "| dias_ultima_consulta      | int64        |\n",
    "| consumo_alcohol           | float64      |\n",
    "| edad                      | int64        |\n",
    "| nivel_estres              | float64      |\n",
    "| genero_M                  | bool         |\n",
    "| target                    | int64        |\n",
    "\n",
    "- La variable `target` representa si un paciente fue o no hospitalizado en los próximos 6 meses.\n",
    "- La variable `genero_M` es una codificación binaria del género (1 para masculino, 0 para femenino)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d540747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    0.504667\n",
      "1    0.495333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data[\"target\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac12f1b",
   "metadata": {},
   "source": [
    "Vemos que la data está muy bien balanceada. La proporción de hospitalizados y no hospitalizados es casi 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c536b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target                  1.000000\n",
      "horas_sueno             0.019934\n",
      "consumo_alcohol         0.018628\n",
      "proteina_c_reactiva     0.009160\n",
      "ratio_colesterol        0.005497\n",
      "nivel_estres            0.001612\n",
      "actividad_fisica        0.001469\n",
      "frecuencia_cardiaca    -0.000867\n",
      "dias_ultima_consulta   -0.002478\n",
      "edad                   -0.004104\n",
      "indice_masa_corporal   -0.016382\n",
      "nivel_glucosa          -0.019268\n",
      "historial_diabetes     -0.033649\n",
      "presion_arterial       -0.038872\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.corr(numeric_only=True)[\"target\"].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0f9aa",
   "metadata": {},
   "source": [
    "Tras calcular la correlación de Pearson entre las variables predictoras y la variable objetivo `target`, observamos que:\n",
    "\n",
    "- Ninguna variable tiene una correlación fuerte (ni siquiera moderada) con `target`.\n",
    "- Las correlaciones son muy cercanas a cero, tanto positivas como negativas.\n",
    "\n",
    "#### ¿Qué significa esto?\n",
    "\n",
    "- No existen relaciones lineales claras entre las variables predictoras y el riesgo de hospitalización.\n",
    "- Sin embargo, **esto no implica que las variables no sean útiles**:\n",
    "  - La **regresión logística no requiere correlaciones lineales fuertes** para funcionar bien.\n",
    "  - Pueden existir relaciones **no lineales o combinaciones** de variables que sí tengan valor predictivo.\n",
    "\n",
    "Por tanto, aún con baja correlación individual, el modelo puede encontrar patrones complejos para predecir adecuadamente la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc21b8",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3abc98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos la columna 'paciente_id' del conjunto de datos, ya que no se utilizará en el modelo.\n",
    "data = data.drop(columns=[\"paciente_id\"])\n",
    "\n",
    "# Convertimos las variables categóricas en variables binarias utilizando one-hot encoding.\n",
    "# 'drop_first=True' asegura que eliminamos una de las categorías para evitar la multicolinealidad.\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Separamos las características (X) de la variable objetivo (y).\n",
    "# 'target' es la variable objetivo, que se elimina de X.\n",
    "X = data.drop(columns=[\"target\"]).values.astype(np.float64)\n",
    "\n",
    "# Normalizamos las características para que todas tengan el mismo rango, usando el escalador.\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Extraemos la variable objetivo (y) y la convertimos a un formato adecuado.\n",
    "y = data[\"target\"].values.reshape(-1, 1).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd617ce",
   "metadata": {},
   "source": [
    "## Modelo logístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2601d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(X, y, weights):\n",
    "    m = X.shape[0]\n",
    "    z = X @ weights\n",
    "    h = sigmoid(z)\n",
    "    epsilon = 1e-15\n",
    "    loss = -(1/m) * np.sum(y * np.log(h + epsilon) + (1 - y) * np.log(1 - h + epsilon))\n",
    "    return loss\n",
    "\n",
    "def train(X, y, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros((n, 1))\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        z = X @ weights\n",
    "        h = sigmoid(z)\n",
    "        gradient = (1/m) * (X.T @ (h - y))\n",
    "        weights -= lr * gradient\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            loss = compute_loss(X, y, weights)\n",
    "            losses.append(loss)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "    return weights\n",
    "\n",
    "def predict(X, weights, threshold=0.5):\n",
    "    probs = sigmoid(X @ weights)\n",
    "    return (probs >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43983a",
   "metadata": {},
   "source": [
    "## Entrenamiento y Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77f99116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6931\n",
      "Epoch 100, Loss: 0.6923\n",
      "Epoch 200, Loss: 0.6918\n",
      "Epoch 300, Loss: 0.6915\n",
      "Epoch 400, Loss: 0.6912\n",
      "Epoch 500, Loss: 0.6911\n",
      "Epoch 600, Loss: 0.6910\n",
      "Epoch 700, Loss: 0.6909\n",
      "Epoch 800, Loss: 0.6909\n",
      "Epoch 900, Loss: 0.6909\n"
     ]
    }
   ],
   "source": [
    "weights = train(X, y, lr=0.01, epochs=1000)\n",
    "y_pred = predict(X, weights).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e3057",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo\n",
    "\n",
    "### Métrica de Evaluación: F1-Score\n",
    "\n",
    "La **F1-Score** es una métrica de evaluación utilizada principalmente en problemas de clasificación binaria, especialmente cuando las clases están desbalanceadas o cuando tanto los **falsos positivos** como los **falsos negativos** son importantes.\n",
    "\n",
    "#### ¿Qué mide?\n",
    "\n",
    "El F1-Score es la **media armónica** entre la **precisión** (*precision*) y la **recuperación** (*recall*):\n",
    "\n",
    "$$\n",
    "\\text{F1} = 2 \\cdot \\frac{\\text{Precisión} \\cdot \\text{Recall}}{\\text{Precisión} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "- **Precisión (Precision)**: Qué proporción de las predicciones positivas fueron realmente positivas.  \n",
    "  $$\n",
    "  \\text{Precisión} = \\frac{TP}{TP + FP}\n",
    "  $$\n",
    "\n",
    "- **Recall (Sensibilidad)**: Qué proporción de los positivos reales fueron correctamente identificados.  \n",
    "  $$\n",
    "  \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "  $$\n",
    "\n",
    "Donde:\n",
    "- `TP`: Verdaderos positivos\n",
    "- `FP`: Falsos positivos\n",
    "- `FN`: Falsos negativos\n",
    "\n",
    "#### ¿Por qué usar F1-Score?\n",
    "\n",
    "- Es útil cuando hay un **desequilibrio entre clases** o cuando **los errores tienen diferentes costos**.\n",
    "- Penaliza los modelos que tienen **alta precisión pero bajo recall** (o viceversa).\n",
    "- Es más informativa que la simple precisión o la exactitud (accuracy) en muchos casos clínicos.\n",
    "\n",
    "#### En este proyecto\n",
    "\n",
    "Dado que queremos predecir **riesgo de hospitalización**, tanto **no detectar un paciente que sí será hospitalizado** como **alertar falsamente a un paciente sano** son errores críticos.  \n",
    "El F1-Score proporciona un **equilibrio** adecuado entre estos dos tipos de errores y es una métrica adecuada para evaluar el modelo de regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "34df5a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5314500110350916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"F1-Score:\", f1_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a65492",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "El modelo de regresión logística desarrollado para predecir el riesgo de hospitalización arrojó un **F1-Score de 0.5315**.\n",
    "\n",
    "### Interpretación:\n",
    "\n",
    "Este valor indica un **desempeño moderado** del modelo, con un balance razonable entre precisión y recall. Aunque el modelo logra identificar correctamente algunos pacientes en riesgo, **aún hay margen significativo de mejora**.\n",
    "\n",
    "Dado que el F1-Score está solo ligeramente por encima de 0.5, esto sugiere que el modelo **no es mucho mejor que una predicción aleatoria**. Esto sugiere que el modelo puede mejorar. Para esto, se puede considerar:\n",
    "\n",
    "- Explorar **transformaciones no lineales** de variables o interacciones entre ellas.\n",
    "- Evaluar la selección de características y eliminar variables irrelevantes.\n",
    "- Ajustar hiperparámetros como la tasa de aprendizaje o el número de iteraciones.\n",
    "- Probar técnicas de **regularización** para mejorar la generalización.\n",
    "\n",
    "Este resultado es un punto de partida útil, pero se requieren mejoras adicionales para que el modelo sea confiable en un entorno clínico real."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
